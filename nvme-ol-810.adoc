---
sidebar: sidebar 
permalink: nvme-ol-810.html 
keywords: nvme, oracle linux, 8.10, host configuration 
summary: 'Configuration d"hôte NVMe-of pour Oracle Linux 8.10 avec ONTAP' 
---
= Configuration d'hôte NVMe-of pour Oracle Linux 8.10 avec ONTAP
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Les configurations hôte SAN de NetApp prennent en charge le protocole NVMe over Fabrics (NVMe-of) avec ANA (Asymmetric Namespace Access). Dans les environnements NVMe-of, ANA équivaut à des chemins d'accès multiples ALUA (Asymmetric Logical Unit Access) dans les environnements iSCSI et FCP. ANA est implémentée à l'aide de la fonctionnalité de chemins d'accès multiples NVMe intégrée au noyau.

.Description de la tâche
Avec la configuration hôte NVMe-of pour Oracle Linux 8.10, vous pouvez utiliser les fonctionnalités et le support suivants : Vous devez également vérifier les limites connues avant de commencer le processus de configuration.

* Support disponible :
+
** Prise en charge de NVMe over TCP (NVMe/TCP) et NVMe over Fibre Channel (NVMe/FC). Cela permet au plug-in NetApp du package nvme-cli natif d'afficher les informations de ONTAP pour les namespaces NVMe/FC et NVMe/TCP.
+
Selon la configuration de l'hôte, vous configurez les protocoles NNMe/FC, NVMe/TCP ou les deux.

** Exécution simultanée du trafic NVMe et SCSI sur le même hôte Par exemple, vous pouvez configurer dm-multipath pour les périphériques SCSI `mpath` pour les LUN SCSI et utiliser le protocole NVMe multipath pour configurer les périphériques d'espace de noms NVMe-of sur l'hôte.


+
Pour plus d'informations sur les configurations prises en charge, reportez-vous au link:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].

* Fonctionnalités disponibles :
+
** La fonctionnalité de chemins d'accès multiples NVMe in-kernel est activée par défaut pour les espaces de noms NVMe dans Oracle Linux 8.10. Il n'est pas nécessaire de configurer des paramètres explicites.


* Limitations connues :
+
** Le démarrage SAN à l'aide du protocole NVMe-of n'est pas pris en charge pour le moment.
** L'utilitaire hôte NetApp sanlun n'est pas pris en charge pour NVMe-of sur un hôte Oracle Linux 8.10. Vous pouvez plutôt vous appuyer sur le plug-in NetApp inclus dans le pack natif `nvme-cli` pour tous les transports NVMe-of.






== Validation des versions logicielles

Validez les versions logicielles minimales prises en charge pour Oracle Linux 8.10.

.Étapes
. Installez Oracle Linux 8.10 GA sur le serveur. Une fois l'installation terminée, vérifiez que vous exécutez le noyau Oracle Linux 8.10 GA spécifié :
+
[listing]
----
uname -r
----
+
[listing]
----
5.15.0-206.153.7.1.el8uek.x86_64
----
. Installer le `nvme-cli` groupe :
+
[listing]
----
rpm -qa|grep nvme-cli
----
+
[listing]
----
nvme-cli-1.16-9.el8.x86_64
----
. Sur l'hôte Oracle Linux 8.10, vérifiez la `hostnqn` chaîne à `/etc/nvme/hostnqn`:
+
[listing]
----
cat /etc/nvme/hostnqn
----
+
[listing]
----
nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
----
. Vérifiez que `hostnqn` sur l'hôte Oracle Linux 8.10 correspond au sous-système correspondant sur `hostnqn` la baie ONTAP :
+
[listing]
----
vserver nvme subsystem host show -vserver vs_coexistence_LPE36002
----
+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
Vserver Subsystem Priority  Host NQN
------- --------- --------  ------------------------------------------------
vs_coexistence_LPE36002
        nvme
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme1
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme2
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
        nvme3
                  regular   nqn.2014-08.org.nvmexpress:uuid:edd38060-00f7-47aa-a9dc-4d8ae0cd969a
4 entries were displayed.
----
====
+

NOTE: Si les `hostnqn` chaînes ne correspondent pas, utilisez la `vserver modify` commande pour mettre à jour la `hostnqn` chaîne sur votre sous-système de matrice ONTAP correspondant afin qu'elle corresponde à la `hostnqn` chaîne de `/etc/nvme/hostnqn` sur l'hôte.

. Si vous avez l'intention d'exécuter le trafic existant NVMe et SCSI sur le même hôte, NetApp recommande d'utiliser le multipath NVMe in-kernel pour les namespaces ONTAP et `dm-multipath` pour les LUN ONTAP, respectivement. Cela doit exclure les espaces de noms ONTAP de `dm-multipath` et empêcher `dm-multipath` de réclamer les périphériques d'espace de noms ONTAP :
+
.. Ajoutez le `enable_foreign` paramètre au `/etc/multipath.conf` fichier :
+
[listing]
----
# cat /etc/multipath.conf
defaults {
  enable_foreign     NONE
}
----
.. Redémarrez le `multipathd` démon pour appliquer le nouveau paramètre :
+
`systemctl restart multipathd`







== Configurez NVMe/FC

Vous pouvez configurer NVMe/FC avec les adaptateurs FC Broadcom/Emulex ou Marvell/Qlogic. Pour le protocole NVMe/FC configuré avec une carte Broadcom, vous pouvez activer des demandes d'E/S d'une taille de 1 Mo.

[role="tabbed-block"]
====
.Broadcom/Emulex
--
Configuration de NVMe/FC pour une carte Broadcom/Emulex

.Étapes
. Vérifiez que vous utilisez le modèle d'adaptateur pris en charge :
+
.. `cat /sys/class/scsi_host/host*/modelname`
+
[listing]
----
LPe36002-M64
LPe36002-M64
----
.. `cat /sys/class/scsi_host/host*/modeldesc`
+
[listing]
----
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
Emulex LPe36002-M64 2-Port 64Gb Fibre Channel Adapter
----


. Vérifiez que vous utilisez la carte Broadcom recommandée `lpfc` micrologiciel et pilote de boîte de réception :
+
.. `cat /sys/class/scsi_host/host*/fwrev`
+
[listing]
----
14.4.317.10, sli-4:6:d
14.4.317.10, sli-4:6:d
----
.. `cat /sys/module/lpfc/version`
+
[listing]
----
0:14.2.0.13
----
+
Pour obtenir la liste actuelle des versions de pilotes et de micrologiciels de carte prises en charge, consultez le link:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].



. Vérifiez que `lpfc_enable_fc4_type` est réglé sur « 3 » :
+
`cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type`

. Vérifier que les ports initiateurs sont opérationnels et que les LIFs cibles sont visibles :
+
.. `cat /sys/class/fc_host/host*/port_name`
+
[listing]
----
0x100000109bf0449c
0x100000109bf0449d
----
.. `cat /sys/class/fc_host/host*/port_state`
+
[listing]
----
Online
Online
----
.. `cat /sys/class/scsi_host/host*/nvme_info`
+
.Montrer l'exemple
[%collapsible]
=====
[listing, subs="+quotes"]
----
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc0 WWPN x100000109bf0449c WWNN x200000109bf0449c DID x061500 *ONLINE*
NVME RPORT       WWPN x200bd039eab31e9c WWNN x2005d039eab31e9c DID x020e06 *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x2006d039eab31e9c WWNN x2005d039eab31e9c DID x020a0a *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 000000002c Cmpl 000000002c Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000000008ffe8 Issue 000000000008ffb9 OutIO ffffffffffffffd1
        abort 0000000c noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 0000000c Err 0000000c
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
NVME LPORT lpfc1 WWPN x100000109bf0449d WWNN x200000109bf0449d DID x062d00 *ONLINE*
NVME RPORT       WWPN x201fd039eab31e9c WWNN x2005d039eab31e9c DID x02090a *TARGET DISCSRVC ONLINE*
NVME RPORT       WWPN x200cd039eab31e9c WWNN x2005d039eab31e9c DID x020d06 *TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000041 Cmpl 0000000041 Abort 00000000
LS XMIT: Err 00000000  CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 00000000000936bf Issue 000000000009369a OutIO ffffffffffffffdb
        abort 00000016 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00000016 Err 00000016
----
=====




--
.Marvell/QLogic
--
Configuration du NVMe/FC pour un adaptateur Marvell/QLogic


NOTE: Le pilote natif de boîte de réception qla2xxx inclus dans le noyau Oracle Linux 10 GA a les derniers correctifs. Ces correctifs sont essentiels à la prise en charge de ONTAP.

.Étapes
. Vérifiez que vous exécutez les versions du pilote de carte et du micrologiciel prises en charge :
+
`cat /sys/class/fc_host/host*/symbolic_name`

+
[listing]
----
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
QLE2772 FW:v9.15.00 DVR:v10.02.09.100-k
----
. Vérifiez que `ql2xnvmeenable` est réglé sur « 1 ». L'adaptateur Marvell peut ainsi fonctionner en tant qu'initiateur NVMe/FC :
+
`cat /sys/module/qla2xxx/parameters/ql2xnvmeenable`



--
====


=== Activation d'une taille d'E/S de 1 Mo (en option)

ONTAP signale une taille de transfert MAX Data (MDT) de 8 dans les données Identify Controller. La taille maximale des demandes d'E/S peut donc atteindre 1 Mo. Pour émettre des demandes d'E/S d'une taille de 1 Mo pour un hôte Broadcom NVMe/FC, augmentez la `lpfc` valeur du `lpfc_sg_seg_cnt` paramètre à 256 par rapport à la valeur par défaut 64.


NOTE: Ces étapes ne s'appliquent pas aux hôtes NVMe/FC Qlogic.

.Étapes
. Réglez le `lpfc_sg_seg_cnt` paramètre sur 256 :
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Exécutez `dracut -f` la commande et redémarrez l'hôte.
. Vérifier que la valeur attendue de `lpfc_sg_seg_cnt` est 256 :
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----




== Configurez NVMe/TCP

Le protocole NVMe/TCP ne prend pas en charge `auto-connect` l'opération. Vous pouvez à la place détecter les sous-systèmes et les espaces de noms NVMe/TCP en exécutant manuellement les opérations NVMe/TCP `connect` ou `connect-all`.

.Étapes
. Vérifiez que le port initiateur peut récupérer les données de la page de journal de découverte sur les LIF NVMe/TCP prises en charge :
+
[listing]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
#	nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24 Discovery Log Number of Records 20, Generation counter 45
=====Discovery Log Entry 0======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  6
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 1======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  1
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.24
sectype: none
=====Discovery Log Entry 2======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  4
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.6.24
sectype: none
=====Discovery Log Entry 3======
trtype:  tcp
adrfam:  ipv4
subtype: unrecognized
treq:    not specified
portid:  2
trsvcid: 8009
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:discovery
traddr:  192.168.5.25
sectype: none
=====Discovery Log Entry 4======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  6
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
traddr:  192.168.6.25
sectype: none
=====Discovery Log Entry 5======
trtype:  tcp
adrfam:  ipv4
subtype: nvme subsystem
treq:    not specified
portid:  1
trsvcid: 4420
subnqn:  nqn.1992-08.com.netapp:sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
..........
----
====
. Vérifier que toutes les autres combinaisons de LIF NVMe/TCP initiator-target peuvent récupérer les données de la page du journal de découverte :
+
[listing]
----
nvme discover -t tcp -w <host-traddr> -a <traddr>
----
+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
# nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.24
# nvme discover -t tcp -w 192.168.6.1 -a 192.168.6.25
# nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.24
# nvme discover -t tcp -w 192.168.5.1 -a 192.168.5.25
----
====
. Lancer `nvme connect-all` la commande sur l'ensemble des LIFs initiator-target-target NVMe/TCP prises en charge sur les nœuds :
+
[listing]
----
nvme connect-all -t tcp -w <host-traddr> -a <traddr> -l <ctrl_loss_timeout_in_seconds>
----
+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
#	nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.24	-l -1
#	nvme	connect-all	-t	tcp	-w	192.168.5.1	-a	192.168.5.25	-l -1
#	nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.24	-l -1
#	nvme	connect-all	-t	tcp	-w	192.168.6.1	-a	192.168.6.25	-l -1
----
====
+

NOTE: NetApp recommande de définir `ctrl-loss-tmo` l'option sur « -1 » afin que l'initiateur NVMe/TCP tente de se reconnecter indéfiniment en cas de perte de chemin.





== Validez la spécification NVMe-of

Pour prendre en charge le bon fonctionnement des LUN ONTAP, vérifiez que l'état des chemins d'accès multiples NVMe dans le noyau, l'état ANA et les namespaces ONTAP sont corrects pour la configuration NVMe-of.

.Étapes
. Vérifiez que le protocole NVMe multipath intégré au noyau est activé :
+
`cat /sys/module/nvme_core/parameters/multipath`

+
`Y`

. Vérifiez que les paramètres NVMe-of (tels que le modèle défini sur « contrôleur NetApp ONTAP » et l'iopole d'équilibrage de la charge défini sur « round-Robin ») des namespaces ONTAP respectifs s'affichent correctement sur l'hôte :
+
.. `cat /sys/class/nvme-subsystem/nvme-subsys*/model`
+
[listing]
----
NetApp ONTAP Controller
NetApp ONTAP Controller
----
.. `cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy`
+
[listing]
----
round-robin
round-robin
----


. Vérifiez que les espaces de noms sont créés et correctement découverts sur l'hôte :
+
`nvme list`

+
.Montrer l'exemple
[%collapsible]
====
[listing]
----
Node         SN                   Model
---------------------------------------------------------
/dev/nvme0n1 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n2 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller
/dev/nvme0n3 814vWBNRwf9HAAAAAAAB NetApp ONTAP Controller

Namespace Usage   Format               FW            Rev
-----------------------------------------------------------
1                 85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF
2                 85.90 GB / 85.90 GB  24 KiB + 0 B  FFFFFFFF
3	                85.90 GB / 85.90 GB  4 KiB + 0 B   FFFFFFFF

----
====
. Vérifiez que l'état du contrôleur de chaque chemin est actif et que l'état ANA est correct :
+
[role="tabbed-block"]
====
.NVMe/FC
--
`nvme list-subsys /dev/nvme0n1`

.Montrer l'exemple
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: 4b4d82566aab11ef9ab8d039eab31e9d:subsystem.nvme\
+-  nvme1 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ad039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live optimized*
+-  nvme2 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203cd039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live optimized*
+- nvme3 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x203ed039eab31e9c host_traddr=nn-0x200034800d756a89:pn-0x210034800d756a89 *live non-optimized*
+-  nvme7 *fc* traddr=nn-0x2038d039eab31e9c:pn-0x2039d039eab31e9c host_traddr=nn-0x200034800d756a88:pn-0x210034800d756a88 *live non-optimized*
----
=====
--
.NVMe/TCP
--
`nvme list-subsys /dev/nvme0n1`

.Montrer l'exemple
[%collapsible]
=====
[listing, subs="+quotes"]
----
nvme-subsys0 - NQN=nqn.1992- 08.com.netapp: sn.e6c438e66ac211ef9ab8d039eab31e9d:subsystem.nvme_tcp_4
\
+- nvme1 *tcp* traddr=192.168.5.25 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live optimized*
+- nvme10 *tcp* traddr=192.168.6.24 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live optimized*
+- nvme2 *tcp* traddr=192.168.5.24 trsvcid=4420 host_traddr=192.168.5.1 src_addr=192.168.5.1 *live non-optimized*
+- nvme9 *tcp* traddr=192.168.6.25 trsvcid=4420 host_traddr=192.168.6.1 src_addr=192.168.6.1 *live non-optimized*
----
=====
--
====
. Vérifier que le plug-in NetApp affiche les valeurs correctes pour chaque périphérique d'espace de noms ONTAP :
+
[role="tabbed-block"]
====
.Colonne
--
`nvme netapp ontapdevices -o column`

.Montrer l'exemple
[%collapsible]
=====
[listing]
----
Device         Vserver                  Namespace Path                NSID UUID                                  Size
-------------- ------------------------ ----------------------------- ---- ------------------------------------- ---------
/dev/nvme0n1   vs_coexistence_QLE2772   /vol/fcnvme_1_1_0/fcnvme_ns   1    159f9f88-be00-4828-aef6-197d289d4bd9  10.74GB
/dev/nvme0n2   vs_coexistence_QLE2772   /vol/fcnvme_1_1_1/fcnvme_ns   2    2c1ef769-10c0-497d-86d7-e84811ed2df6  10.74GB
/dev/nvme0n3   vs_coexistence_QLE2772   /vol/fcnvme_1_1_2/fcnvme_ns   3    9b49bf1a-8a08-4fa8-baf0-6ec6332ad5a4  10.74GB
----
=====
--
.JSON
--
`nvme netapp ontapdevices -o json`

.Montrer l'exemple
[%collapsible]
=====
[listing]
----
{
  "ONTAPdevices" : [
    {
      "Device" : "/dev/nvme0n1",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_0/fcnvme_ns",
      "NSID" : 1,
      "UUID" : "159f9f88-be00-4828-aef6-197d289d4bd9",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n2",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_1/fcnvme_ns",
      "NSID" : 2,
      "UUID" : "2c1ef769-10c0-497d-86d7-e84811ed2df6",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
    {
      "Device" : "/dev/nvme0n4",
      "Vserver" : "vs_coexistence_QLE2772",
      "Namespace_Path" : "/vol/fcnvme_1_1_3/fcnvme_ns",
      "NSID" : 4,
      "UUID" : "f3572189-2968-41bc-972a-9ee442dfaed7",
      "Size" : "10.74GB",
      "LBA_Data_Size" : 4096,
      "Namespace_Size" : 2621440
    },
----
=====
--
====




== Problèmes connus

La configuration hôte NVMe-of pour Oracle Linux 8.10 avec ONTAP version présente le problème connu suivant :

[cols="1a,4a,4a, options="]
|===
| ID de bug NetApp | Titre | Description 


 a| 
CONTAPEXT-1082
 a| 
Les hôtes Oracle Linux 8.10 NVMe-of créent des CDP dupliqués
 a| 
Sur les hôtes Oracle Linux 8.10 NVMe-of, les contrôleurs de découverte permanente (CDP) sont créés à l'aide de l' `-p`option avec `nvme discover` la commande. Pour une combinaison initiateur-cible donnée, chaque exécution de la `nvme discover` commande doit créer un PDC. Toutefois, à partir d'Oracle Linux 8.x, les hôtes NVMe-of créent un PDC en double. Cela gaspille des ressources sur l'hôte et sur la cible.

|===