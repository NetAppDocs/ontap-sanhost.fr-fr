---
sidebar: sidebar 
permalink: nvme_ol_77.html 
keywords: nvme, linux, oracle, 7.7 
summary: Décrit la configuration de NVMe/FC pour Oracle Linux 7.7 avec ONTAP 
---
= Configuration d'hôte NVMe/FC pour Oracle Linux 7.7 avec ONTAP
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Vous pouvez configurer NVMe over Fibre Channel (NVMe/FC) sur des hôtes initiateurs exécutant Oracle Linux 7.7 et ONTAP comme cible.



== Prise en charge

NVMe/FC est pris en charge sur ONTAP 9.6 ou version ultérieure pour Oracle Linux 7.7. L'hôte Oracle Linux 7.7 peut exécuter le trafic NVMe et SCSI via les mêmes ports d'adaptateur d'initiateur Fibre Channel. Consultez la link:https://hwu.netapp.com/Home/Index["Hardware Universe"^] pour obtenir la liste des adaptateurs et contrôleurs FC pris en charge. Pour obtenir la liste la plus récente des configurations prises en charge, reportez-vous au link:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].


NOTE: Vous pouvez utiliser les paramètres de configuration fournis dans ce document pour configurer les clients Cloud connectés à link:https://docs.netapp.com/us-en/cloud-manager-cloud-volumes-ontap/index.html["Cloud Volumes ONTAP"^] et link:https://docs.netapp.com/us-en/cloud-manager-fsx-ontap/index.html["Amazon FSX pour ONTAP"^].



== Limites connues

* Les scripts natifs de connexion automatique NVMe/FC ne sont pas disponibles dans le pack nvme-cli. Vous pouvez utiliser les scripts de connexion automatique externes fournis par le fournisseur de l'adaptateur HBA.
* Par défaut, l'équilibrage de la charge Round-Robin n'est pas activé. Vous devez écrire une règle udev pour activer cette fonctionnalité. Des étapes sont décrites dans la section relative à l'activation de NVMe/FC sur OL 7.7.
* Le démarrage SAN à l'aide du protocole NVMe-of n'est pas pris en charge pour le moment.




== Activation de NVMe sur OL 7.7

. Assurez-vous que le noyau Oracle Linux 7.7 par défaut est installé.
. Redémarrez l'hôte et vérifiez qu'il démarre dans le noyau OL 7.7 spécifié.
+
[listing]
----
# uname -r
4.14.35-1902.9.2.el7uek
----
. Mise à niveau vers le package nvme-cli-1.8.1-3.el7.
+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.8.1-3.el7.x86_64
----
. Ajoutez la chaîne ci-dessous en tant que règle udev séparée à `/lib/udev/rules.d/71-nvme-iopolicy-netapp-ONTAP.rules`. Cela permet d'équilibrer la charge Round-Robin pour les chemins d'accès multiples NVMe.
+
[listing]
----
# Enable round-robin for NetApp ONTAP
ACTION==”add”, SUBSYSTEM==”nvme-subsystem”, ATTR{model}==”NetApp ONTAP Controller”, ATTR{iopolicy}=”round-robin
----
. Sur l'hôte OL 7.7, vérifiez la chaîne NQN hôte à `/etc/nvme/hostnqn` Et vérifiez qu'il correspond à la chaîne NQN hôte pour le sous-système correspondant de la matrice ONTAP.
+
[listing]
----
# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:75953f3b-77fe-4e03-bf3c-09d5a156fbcd
----
+
[listing]
----
*> vserver nvme subsystem host show -vserver vs_nvme_10
Vserver Subsystem Host NQN
------- --------- -------------------------------------- -----------
ol_157_nvme_ss_10_0
nqn.2014-08.org.nvmexpress:uuid:75953f3b-77fe-4e03-bf3c-09d5a156fbcd
----



NOTE: Si les chaînes NQN hôte ne correspondent pas, vous devez utiliser la commande vserver modify pour mettre à jour la chaîne NQN hôte sur le sous-système de la baie ONTAP correspondant afin qu'elle corresponde à la chaîne NQN hôte à partir de `/etc/nvme/hostnqn` sur l'hôte.

. Redémarrez l'hôte.




== Configuration de l'adaptateur FC Broadcom pour NVMe/FC

. Vérifiez que vous utilisez la carte prise en charge. Pour consulter la liste la plus récente des cartes prises en charge, reportez-vous à la section link:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2
----
+
[listing]
----
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Copiez et installez le package de scripts de connexion automatique de la boîte d'envoi Broadcom.
+
[listing]
----
# rpm -ivh nvmefc-connect-12.4.65.0-1.noarch.rpm
----
. Redémarrez l'hôte.
. Vérifiez que vous utilisez les versions recommandées du micrologiciel Lpfc Broadcom, du pilote natif de la boîte de réception et du boîtier de connexion automatique. Pour obtenir la liste des versions prises en charge, reportez-vous à la section link:https://mysupport.netapp.com/matrix/["Matrice d'interopérabilité NetApp"^].
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.4.243.17, sil-4.2.c
12.4.243.17, sil-4.2.c

# cat /sys/module/lpfc/version
0:12.0.0.10

# rpm -qa | grep nvmefc
nvmefc-connect-12.4.65.0-1.noarch
----
. Vérifiez que lpfc_enable_fc4_type est défini sur 3.
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Vérifiez que les ports initiateurs sont opérationnels.
+
[listing]
----
# cat /sys/class/fc_host/host*/port_name
0x10000090fae0ec61
0x10000090fae0ec62
----
+
[listing]
----
# cat /sys/class/fc_host/host*/port_state
Online
Online
----
. Vérifiez que les ports initiateurs NVMe/FC sont activés, s'exécutant et qu'ils peuvent voir les LIF cibles.
+
[listing]
----
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 NVME 2947 SCSI 2977 ELS 250
NVME LPORT lpfc0 WWPN x10000090fae0ec61 WWNN x20000090fae0ec61 DID x012000 ONLINE
NVME RPORT WWPN x202d00a098c80f09 WWNN x202c00a098c80f09 DID x010201 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203100a098c80f09 WWNN x202c00a098c80f09 DID x010601 TARGET DISCSRVC ONLINE
NVME Statistics
…
----




== Validation des protocoles NVMe/FC

. Vérifiez les paramètres NVMe/FC suivants.
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y

# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller

# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Vérifier que les espaces de noms sont créés.
+
[listing]
----
# nvme list
Node SN Model Namespace Usage Format FW Rev
---------------- -------------------- -----------------------
/dev/nvme0n1 80BADBKnB/JvAAAAAAAC NetApp ONTAP Controller 1 53.69 GB / 53.69 GB 4 KiB + 0 B FFFFFFFF
----
. Vérifiez le statut des chemins ANA.
+
[listing]
----
# nvme list-subsys/dev/nvme0n1
Nvme-subsysf0 – NQN=nqn.1992-08.com.netapp:sn.341541339b9511e8a9b500a098c80f09:subsystem.ol_157_nvme_ss_10_0
\
+- nvme0 fc traddr=nn-0x202c00a098c80f09:pn-0x202d00a098c80f09 host_traddr=nn-0x20000090fae0ec61:pn-0x10000090fae0ec61 live optimized
+- nvme1 fc traddr=nn-0x207300a098dfdd91:pn-0x207600a098dfdd91 host_traddr=nn-0x200000109b1c1204:pn-0x100000109b1c1204 live inaccessible
+- nvme2 fc traddr=nn-0x207300a098dfdd91:pn-0x207500a098dfdd91 host_traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live optimized
+- nvme3 fc traddr=nn-0x207300a098dfdd91:pn-0x207700a098dfdd91 host traddr=nn-0x200000109b1c1205:pn-0x100000109b1c1205 live inaccessible
----
. Vérifier le plug-in NetApp pour les systèmes ONTAP.
+
[listing]
----
# nvme netapp ontapdevices -o column
Device   Vserver  Namespace Path             NSID   UUID   Size
-------  -------- -------------------------  ------ ----- -----
/dev/nvme0n1   vs_nvme_10       /vol/rhel_141_vol_10_0/ol_157_ns_10_0    1        55baf453-f629-4a18-9364-b6aee3f50dad   53.69GB

# nvme netapp ontapdevices -o json
{
   "ONTAPdevices" : [
   {
        Device" : "/dev/nvme0n1",
        "Vserver" : "vs_nvme_10",
        "Namespace_Path" : "/vol/rhel_141_vol_10_0/ol_157_ns_10_0",
         "NSID" : 1,
         "UUID" : "55baf453-f629-4a18-9364-b6aee3f50dad",
         "Size" : "53.69GB",
         "LBA_Data_Size" : 4096,
         "Namespace_Size" : 13107200
    }
]
----




== Activation d'une taille d'E/S de 1 Mo pour Broadcom NVMe/FC

ONTAP signale une taille de transfert MAX Data (MDT) de 8 dans les données Identify Controller. La taille maximale des demandes d'E/S peut donc atteindre 1 Mo. Pour émettre des demandes d'E/S d'une taille de 1 Mo pour un hôte Broadcom NVMe/FC, vous devez augmenter la `lpfc` valeur du `lpfc_sg_seg_cnt` paramètre à 256 par rapport à la valeur par défaut 64.


NOTE: Les étapes suivantes ne s'appliquent pas aux hôtes NVMe/FC Qlogic.

.Étapes
. Réglez le `lpfc_sg_seg_cnt` paramètre sur 256 :
+
[listing]
----
cat /etc/modprobe.d/lpfc.conf
----
+
.Exemple de sortie
[listing]
----
options lpfc lpfc_sg_seg_cnt=256
----
. Lancer `dracut -f` la commande et redémarrer l'hôte :
. Vérifiez que `lpfc_sg_seg_cnt` est 256 :
+
[listing]
----
cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
----
+
La valeur attendue est 256.





== Consignation détaillée LPFC

Définissez le pilote lpfc pour NVMe/FC.

.Étapes
. Réglez le `lpfc_log_verbose` Paramètre du pilote sur l'une des valeurs suivantes pour enregistrer les événements NVMe/FC.
+
[listing]
----
#define LOG_NVME 0x00100000 /* NVME general events. */
#define LOG_NVME_DISC 0x00200000 /* NVME Discovery/Connect events. */
#define LOG_NVME_ABTS 0x00400000 /* NVME ABTS events. */
#define LOG_NVME_IOERR 0x00800000 /* NVME IO Error events. */
----
. Une fois les valeurs définies, exécutez le `dracut-f` commande et redémarre l'hôte.
. Vérifiez les paramètres.
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf options lpfc lpfc_log_verbose=0xf00083

# cat /sys/module/lpfc/parameters/lpfc_log_verbose 15728771
----

